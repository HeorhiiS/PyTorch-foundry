{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkBSWHH47lGnOHBQlX8KfG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QeAvHqGxUyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAr3La0WxaOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  '''\n",
        "Sigmoid \n",
        "\n",
        "x: torch.Tensor\n",
        "\n",
        "  '''\n",
        "  return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acc6bGYBYlwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate dummy data\n",
        "\n",
        "torch.manual_seed(7)\n",
        "\n",
        "features = torch.randn((1,5)) #input\n",
        "\n",
        "weights = torch.randn_like(features) #weights are derived from features\n",
        "\n",
        "bias = torch.randn((1,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90uoHMxrbZk2",
        "colab_type": "code",
        "outputId": "e881b3f8-aab5-436f-afd6-dd0160da9d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(torch.mm(features,weights.T)) # .T for transpose same as in numpy\n",
        "#perceptron\n",
        "\n",
        "y_hat = activation(torch.sum(features * weights) + bias) # * operator for element-wise muliplication (Hadamard product) \n",
        "print(y_hat)\n",
        "\n",
        "print(activation(torch.mm(features,weights.T)+bias))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.9796]])\n",
            "tensor([[0.1595]])\n",
            "tensor([[0.1595]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPBrIa0Wb7AK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multilayer\n",
        "\n",
        "features = torch.randn((1,3))\n",
        "\n",
        "hidden =2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_l9KyZMy49",
        "colab_type": "code",
        "outputId": "5a2272a2-c223-4e5e-94fe-9b44084eb6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zL8RPr4PEna",
        "colab_type": "code",
        "outputId": "bea66c83-810d-4703-d72c-32839e332618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsa-dzCVPKLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b1e09227-a845-42af-f5c9-db5964e1f2c6"
      },
      "source": [
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0)\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 359.89532470703125\n",
            "199 0.7768354415893555\n",
            "299 0.0023894943296909332\n",
            "399 8.055055513978004e-05\n",
            "499 1.9387622160138562e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwy8j0H8lPnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}