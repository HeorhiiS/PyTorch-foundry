# -*- coding: utf-8 -*-
"""NN_basic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qIyHoYjMm__zSJEfmClZZ0wUBCc6BbTj
"""

import torch

def activation(x):
  '''
Sigmoid 

x: torch.Tensor

  '''
  return 1/(1+torch.exp(-x))

#Generate dummy data

torch.manual_seed(7)

features = torch.randn((1,5)) #input

weights = torch.randn_like(features) #weights are derived from features

bias = torch.randn((1,1))

print(torch.mm(features,weights.T)) # .T for transpose same as in numpy
#perceptron

y_hat = activation(torch.sum(features * weights) + bias) # * operator for element-wise muliplication (Hadamard product) 
print(y_hat)

print(activation(torch.mm(features,weights.T)+bias))

# multilayer

features = torch.randn((1,3))

hidden =2

x = torch.ones(2, 2, requires_grad=True)
print(x)

y = x + 2
print(y)

